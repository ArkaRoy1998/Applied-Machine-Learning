{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aadc9af-b638-4a4c-9cb3-f8eb425725a0",
   "metadata": {},
   "source": [
    "### Here we are using different models than the models used to train for assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c5c791-1d9b-460d-b6a7-e4bac3f0382a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sentence-transformers) (0.26.5)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Installing collected packages: tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "Successfully installed sentence-transformers-3.4.1 tokenizers-0.21.0 transformers-4.49.0\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-2.20.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==2.20.3 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.20.3-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: Flask<4 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (3.1.4)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (2.0.2)\n",
      "Requirement already satisfied: pandas<3 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (18.1.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow) (1.13.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.7)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading databricks_sdk-0.44.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (8.5.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging<25 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (5.28.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.20.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/Base_2/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n",
      "Downloading mlflow-2.20.3-py3-none-any.whl (28.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.20.3-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.44.1-py3-none-any.whl (648 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.7/648.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: sqlparse, sqlalchemy, Mako, gunicorn, graphql-core, deprecated, cloudpickle, opentelemetry-api, graphql-relay, docker, alembic, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Mako-1.3.9 alembic-1.14.1 cloudpickle-3.1.1 databricks-sdk-0.44.1 deprecated-1.2.18 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.20.3 mlflow-skinny-2.20.3 opentelemetry-api-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 sqlalchemy-2.0.38 sqlparse-0.5.3\n"
     ]
    }
   ],
   "source": [
    " ! pip install sentence-transformers\n",
    " ! pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbdaa36-7bdd-4763-ab96-7303a57194c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "from sklearn.utils import resample \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parsing URLs\n",
    "from urllib.parse import urlparse  \n",
    "\n",
    "# SentenceTransformer for text embeddings\n",
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "# Scikit-learn for various ML models \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.svm import SVC    \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier \n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve, auc   \n",
    "\n",
    "# MLflow for experiment tracking\n",
    "import mlflow \n",
    "\n",
    "# Joblib for saving and loading models\n",
    "import joblib  \n",
    "\n",
    "# Python logging m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab611d5-e990-451b-ac1f-d633b79dd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_vectors(data, filename):\n",
    "    \"\"\"\n",
    "    Convert text data to sentence vectors using SentenceTransformer model and store in a file.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    data = data.replace(np.nan, '', regex=True)\n",
    "    vectors = model.encode(data['text'])\n",
    "\n",
    "    # Store vectors in a file\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(vectors, file)\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079e6043-77e3-4153-b690-05cbd4d1f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf, param_grid, train_emb, val_emb, test_emb, y_train, y_val, y_test):\n",
    "    \"\"\"\n",
    "    Train a model with hyperparameter tuning on embedded training data and evaluate performance on validation and test sets.\n",
    "    \"\"\"\n",
    "    # Parameter tuning with validation set\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(val_emb, y_val)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Train the model on combined training and validation data with best parameters\n",
    "    clf.set_params(**best_params)\n",
    "    clf.fit(train_emb, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(test_emb)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Evaluate precision-recall curve AUC for binary classification predictions\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    aucpr = auc(recall, precision)\n",
    "\n",
    "    return clf, acc, aucpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797fce02-6eca-4cea-965b-cb68a3767c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_metrics(model, acc, aucpr, model_name):\n",
    "    \"\"\"\n",
    "    Log model metrics and artifacts using MLflow.\n",
    "    \"\"\"\n",
    "    filename = model_name + \".joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"AUCPR: {aucpr}\")\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"model\", filename)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "\n",
    "        # Log artifact\n",
    "        mlflow.log_artifact(filename)\n",
    "\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        # Get the MLflow tracking URI scheme\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=model_name + \"_Model\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f75109-528a-4aba-a3d1-8c60f6d62998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_version(model_name):\n",
    "    \"\"\"\n",
    "    Retrieve the latest version of a model from MLflow by its name.\n",
    "    \"\"\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0].version\n",
    "    return model_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f2aef-fbb2-4473-bee8-d6be39e63d70",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75101631-4ec9-4360-ace7-3fe9ab45fa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06437393, -0.05329217,  0.05308124, ..., -0.0481124 ,\n",
       "        -0.11354938,  0.01842844],\n",
       "       [-0.00070231,  0.04682585,  0.04150278, ..., -0.06567338,\n",
       "         0.07070542,  0.07212626],\n",
       "       [-0.02298434, -0.05006471,  0.02371489, ..., -0.02528759,\n",
       "        -0.10597737, -0.00363031],\n",
       "       ...,\n",
       "       [ 0.04190622,  0.0892358 ,  0.01323775, ...,  0.01013731,\n",
       "        -0.01525157, -0.10524866],\n",
       "       [-0.04490845, -0.04449276,  0.03015462, ...,  0.01425023,\n",
       "        -0.04494065, -0.03324023],\n",
       "       [-0.11006838, -0.05572332, -0.00285661, ..., -0.05245342,\n",
       "        -0.11218999, -0.07318109]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#Load data\n",
    "train = pd.read_csv(\"Data/Training Data.csv\")\n",
    "val = pd.read_csv(\"Data/Validation Data.csv\")\n",
    "test = pd.read_csv(\"Data/Test Data.csv\")\n",
    "\n",
    "\n",
    "# # Convert text to vectors and store them\n",
    "convert_text_to_vectors(train, 'train_emb.pkl')\n",
    "convert_text_to_vectors(val, 'val_emb.pkl')\n",
    "convert_text_to_vectors(test, 'test_emb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6a3b43-e708-453d-8b07-3e850405cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectors from files\n",
    "with open('train_emb.pkl', 'rb') as file:\n",
    "    train_emb = pickle.load(file)\n",
    "\n",
    "with open('val_emb.pkl', 'rb') as file:\n",
    "    val_emb = pickle.load(file)\n",
    "\n",
    "with open('test_emb.pkl', 'rb') as file:\n",
    "    test_emb = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4102f-7a2a-4099-a089-4b9a00a5bcd4",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db6ed1-ef7f-48f1-bb4c-194ef875204d",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476a6b0e-52bb-48bb-bddb-cd3b19f67aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9820574162679426\n",
      "AUCPR: 0.9392165610586662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 03:43:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 03:43:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Logistic_Regression_Model'.\n",
      "Created version '1' of model 'Logistic_Regression_Model'.\n",
      "/var/folders/sn/vbyzg70d21x5fd47t98yw3p00000gn/T/ipykernel_26386/3093244033.py:7: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0].version\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Logistic_Regression\"\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear'], \n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Convert labels to binary (0 for ham, 1 for spam)\n",
    "y_train = train['spam'].map({'ham': 0, 'spam': 1})\n",
    "y_val = val['spam'].map({'ham': 0, 'spam': 1})\n",
    "y_test = test['spam'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Train the model\n",
    "lr_model, lr_acc, lr_aucpr = train_model(\n",
    "    clf, param_grid_lr, train_emb, val_emb, test_emb, \n",
    "    y_train, y_val, y_test\n",
    ")\n",
    "\n",
    "log_model_metrics(lr_model, lr_acc, lr_aucpr, model_name)\n",
    "\n",
    "version = get_model_version(model_name + \"_Model\")\n",
    "print(f\"Model Version: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c837d3b-01d8-45eb-b5be-d7990b1f970f",
   "metadata": {},
   "source": [
    "### 2 . Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1248c28-d5d6-4525-a37e-9bfc91a63d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 03:45:42 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1f8d3f5e4da547e9a093a69804115b19', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/03/05 03:45:42 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025/03/05 03:45:51 INFO mlflow.sklearn.utils: Logging the 5 best runs, 19 runs will be omitted.\n",
      "2025/03/05 03:45:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f9cacb17f4d64a448ed14747fa6a228a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/03/05 03:45:51 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9760765550239234\n",
      "AUCPR: 0.9158907711539291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 03:45:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 03:45:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Support_Vector_Machine_Model'.\n",
      "Created version '1' of model 'Support_Vector_Machine_Model'.\n",
      "/var/folders/sn/vbyzg70d21x5fd47t98yw3p00000gn/T/ipykernel_26386/3093244033.py:7: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0].version\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Support_Vector_Machine\"\n",
    "clf = SVC()\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Convert labels to binary (0 for ham, 1 for spam)\n",
    "y_train = train['spam'].map({'ham': 0, 'spam': 1})\n",
    "y_val = val['spam'].map({'ham': 0, 'spam': 1})\n",
    "y_test = test['spam'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Train the model\n",
    "svm_model, svm_acc, svm_aucpr = train_model(\n",
    "    clf, param_grid_svc, train_emb, val_emb, test_emb, \n",
    "    y_train, y_val, y_test  # Use numerical labels here\n",
    ")\n",
    "\n",
    "log_model_metrics(svm_model, svm_acc, svm_aucpr, model_name)\n",
    "\n",
    "version = get_model_version(model_name + \"_Model\")\n",
    "print(f\"Model Version: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e260444-cd1a-4f89-a42c-28157ddf0d17",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe7080ff-82e3-477f-96a7-562ede696c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 03:50:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a53e566349624fcaa1143cc97d946306', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/03/05 03:50:33 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025/03/05 04:13:41 INFO mlflow.sklearn.utils: Logging the 5 best runs, 211 runs will be omitted.\n",
      "2025/03/05 04:13:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '69cb41f2728642fba8d9616cc38ebcc8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/03/05 04:13:41 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9593301435406698\n",
      "AUCPR: 0.867181775076512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 04:13:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 04:13:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random_Forest_Model'.\n",
      "Created version '1' of model 'Random_Forest_Model'.\n",
      "/var/folders/sn/vbyzg70d21x5fd47t98yw3p00000gn/T/ipykernel_26386/3093244033.py:7: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0].version\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Random_Forest\"\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=6, random_state=101)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Convert labels to binary (0 for ham, 1 for spam)\n",
    "y_train = train['spam'].map({'ham': 0, 'spam': 1})\n",
    "y_val = val['spam'].map({'ham': 0, 'spam': 1})\n",
    "y_test = test['spam'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Train the model\n",
    "rf_model, rf_acc, rf_aucpr = train_model(\n",
    "    clf, param_grid_rf, train_emb, val_emb, test_emb, \n",
    "    y_train, y_val, y_test  # Use numerical labels here\n",
    ")\n",
    "\n",
    "log_model_metrics(rf_model, rf_acc, rf_aucpr, model_name)\n",
    "\n",
    "version = get_model_version(model_name + \"_Model\")\n",
    "print(f\"Model Version: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070a397-dbed-4add-a236-e66a765e4a0d",
   "metadata": {},
   "source": [
    "### 4. Ensemble Modeling: Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a08348-0b61-4308-b1f7-34769a17a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 04:20:59 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5d546c95e7bd4418a01657edb8dd0151', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025/03/05 04:26:00 INFO mlflow.sklearn.utils: Logging the 5 best runs, 19 runs will be omitted.\n",
      "2025/03/05 04:26:00 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0919e9ab1bbf494386c591bd113911cd', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9868421052631579\n",
      "AUCPR: 0.9560338554146605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 04:26:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/03/05 04:26:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Stacking_Classifier_Model'.\n",
      "Created version '1' of model 'Stacking_Classifier_Model'.\n",
      "/var/folders/sn/vbyzg70d21x5fd47t98yw3p00000gn/T/ipykernel_26386/3093244033.py:7: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0].version\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Stacking_Classifier\"\n",
    "\n",
    "# Convert labels to binary and ensure numpy arrays\n",
    "y_train = train['spam'].map({'ham': 0, 'spam': 1}).values\n",
    "y_val = val['spam'].map({'ham': 0, 'spam': 1}).values\n",
    "y_test = test['spam'].map({'ham': 0, 'spam': 1}).values\n",
    "\n",
    "# Define base estimators (enable probability for SVM)\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('svm', SVC(probability=True)),  # Required for `predict_proba`\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=101))\n",
    "]\n",
    "\n",
    "# Define the stacking classifier\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    stack_method='auto',\n",
    "    cv=3,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid_stack = {\n",
    "    'stack_method': ['auto', 'predict_proba'],\n",
    "    'final_estimator': [LogisticRegression(), RandomForestClassifier()],\n",
    "    'cv': [2, 3, 5],  # Remove invalid parameters like `final_estimator__max_iter`\n",
    "    'passthrough': [False, True]\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "stacking_model, stacking_acc, stacking_aucpr = train_model(\n",
    "    clf, param_grid_stack, train_emb, val_emb, test_emb, \n",
    "    y_train, y_val, y_test\n",
    ")\n",
    "\n",
    "log_model_metrics(stacking_model, stacking_acc, stacking_aucpr, model_name)\n",
    "\n",
    "version = get_model_version(model_name + \"_Model\")\n",
    "print(f\"Model Version: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa5a84-be9b-47af-b86e-ebf99aec5fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
